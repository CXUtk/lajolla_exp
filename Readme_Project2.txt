# Part 2
1. When absorption is zero, I saw a bright circle with uniform color. This is because the transmittance will always be 1 if sigma_t is equal to 1.
2. To take emission into account, for each segment of ray that passes through a medium, we add the emission per unit length times the travel distance to the radiance for this path. Note that instead of multiplying the transmittance, we directly add the radiance contribution. 

# Part 3
1. We normalize the function value so that the integral of the function in whole domain is equal to 1. In this case, the integral from 0 to infinity of exp(-sigma_t * t) dt is exp(-sigma_t * t) / sigma_t, to normalize the function we need to multiply the original function by sigma_t.
2. Once we sample the next distance to be greater or equal to the closest surface, we assume that all of such distance share the same sampling result. Therefore, if we hit a surface, the pdf for this case is the probability of sampling a distance greater or equal to the distance to the closest surface. We can correctly address the pdf for such a discrete event in this case. 
3. When sigma_a increase, the image becomes darker. This is because the medium absorbs more light. When sigma_a increase, the image will also be darker, but at the same time I can also see the light is spreading. This is because out-scattering will lose light energy, but the light passes medium also gain energy from in-scattering. 
4. The parameter g in the Henyey-Greenstein model is a measure of the anisotropy of scattering. It determines how much the scattered light is preferentially directed in the forward or backward direction relative to the incident light. When I set g to be positive, I observed the image to be brighter to the color of the light sphere. On the other hand, if I set g to be negative, the image will be darker. This is because when we prefer forward direction, we will have greater contribution from the light sphere in front of the camera. When we prefer backward direction, we will have less contribution from the light. 

# Part 4
1. By decreasing sigma_a and sigma_s for medium 1, I found the light sphere becomes brighter while the environment becomes darker. The brightness for the translucent sphere also decreased. This is because the scattering of the medium outside the sphere is decreased, less light will be spread to the free space. By decreasing sigma_a and sigma_s for medium 2, it also allows more light to pass through the translucent sphere, which makes the sphere more transparent. I also noticed that if I set sigma_s high and sigma_a low for medium 2, the sphere looks like a rough surfacce. This is beacuse the scattering event happens near the surface of the sphere, which is also how surface scattering of diffused material behave. 
When I set sigma_a and sigma_s high, increasing the max_depth will make the image becomes brighter, but it is not so obvious when sigma_a and sigma_s are low. Therefore, it seems that max_depth will have greater impact when we have large value of sigma_t. 
2. If I set g to be positive, the entire translucent sphere will becomes brighter. If I set g to be negative, the translucent sphere will becomes darker. This is beacuse the light source is behind the object, so forward-preferred phase function would have large contribution from the light source and backward-preferred phase function would have less contribution from the light source. 
3. I would first measure some of the phase function in real world and consider a analytical function to fit the measured result. There are serveral factors I want to consider:
    1. Anisotropy of scattering: I want to control whether the phase function prefer forward direction or bacckward direction, this is similar to Henyey-Greenstein model. I can also have parameter to control whether it prefer to scatter in other direction (eg. perpendicular to the light direcion). 
    2. Wavelength: Different wavelength may have different behavior on their scattering process. Therefore, I would like to have the shape of the phase function tuned by the wavelength value. 
    3. Easy to sample: I would like this function to have an analytical form for the function itself and its integral around the unit sphere. This makes the phase function easy to use in practice. 

 

# Part 5
1. In our test scene, next event estimation is more efficient. This is bacause one of the light source is small, which will take a lot of phase function sampling steps to reach, especially when the phase function is isotropic. But using next event estimation we can efficiently capture the path to that small light source. However, next event estimation is not necessarily more efficient than phase function sampling in general. It really depends on scene geometry and different kinds of phase function. If we have a anisotropic phase function that have most weight on one direction, then phase function sampling is more efficient because it has greater chance to sample the path with most contribution.
2. I would say that they are very similar. Because the underlying principle of the diffuse reflection surface is that the light enters the surface and then bounces out (possibly many bounces). The only difference I noticed is around the edge of lighting area, Lambertian matrial will have shaper edge than the volume approach. This is probably because the light can go out from the surface even if the point is in shadow. 
3. The interaction of light with the surface of the object is essentially the process of scattering in the volume, we can model almost every material realistically using volume rendering. That's one of the reason he made this prediction, it's also possible that the increasing power and availability 
of computers makes him condident that there will be enough computation power in the future. 
volume rendering has not yet become the dominant form of rendering may because of the following reasons:
    1. The computation power does not improve as much as imagined.
    2. Many new approximation and sampling techniques could give a plausible result in a much more efficient way. 
    3. It is hard to develop correct model using volume rendering. 

# Part 6
1. Smaller index of refraction will have a more spread out of lighting while larger index of refraction will produce an image that the light is concentrated in the middle. This is because the change of index of refraction will also change the behavior of the Fresnel term, which controls how much light is reflect from the surface. When we have high index of refraction, most of the light will come from reflection, therefore the image is bright in the middle. If we have low index of refraction, most of the light will refract into the surface, which will pass through the volume and scatter. That's why we see the ring around the bright center.
2. If we use blue glass, the color is constant on object with different thickness. But if we use volume rendering approach, the thick part will have darker color while the think part is more transparent. The former looks like a very thin shell while the later looks like a uniform object. This color that changes with thickness can greatly increase the realism of the object.

# Part 7
1. When the volume is relatively homogeneous (eg. have the most of sigma_t to be equal to the majorant), the algorithm is the most efficient. But if the volume have a tiny area equal to majorant and other area have much smaller sigma_t, the algorithm will be inefficient because it will reject the sample most of the time. To improve the efficiency, we can subdivide the volume into different parts so that each region have sigma_t that does not vary much. That is saying using local density majorant instead of global majorant. 
2. Since emission is added linearly with respect to t, we can sample the emission value separately from the scattering sampling process. But to make the null-scattering work, we can also add emission particle to the the volume. Specifically, we make majorant equals to the maximum of sigma_t + sigma_e. Now besides hitting a surface, 3 things could happen hit a real particle, hit a fake particle or hit a emission particle. When we hit a emission particle, we continue with next sampling of scattering event, but also add the emission for this segment to the emission cache. Finally, we use the emission cache and pdf to compute the contribution to final radiance.
3. It's important to have unbiased solution for volume rendering because sometimes we need an accurate and physically correct result. Depending on the usage, it could be sensible to have something biased but fast, such as rendering in games and movies. On the other hand, if the results will be used for scientific or engineering analysis, where accuracy and fidelity are critical, we have to use unbiased method.
For the biased method, I would think of using a simpler model or doing pre-integration of a given volume object. After doing the pre-integration, we have an approximation transport function for this object, and when we do rendering, we interpolation between pre-integrated results. 

# Bonus
See image.exr, using the scene 'scenes/self_tasks/livingRoom2.xml'